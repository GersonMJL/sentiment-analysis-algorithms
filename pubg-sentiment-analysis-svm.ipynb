{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a38f574",
   "metadata": {},
   "source": [
    "# Steam Reviews Sentiment Analysis for PUBG: Battlegrounds using SVM\n",
    "\n",
    "This notebook performs sentiment analysis on Steam reviews for PUBG: Battlegrounds using a Support Vector Machine (SVM) algorithm. We'll load the reviews from a parquet file, preprocess the text data, and train an SVM model to classify reviews as positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4217da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Gerson\n",
      "[nltk_data]     Leite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Gerson\n",
      "[nltk_data]     Leite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Gerson\n",
      "[nltk_data]     Leite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Gerson Leite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a930e47",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "Before training our SVM model, we need to preprocess the review text by:\n",
    "1. Converting to lowercase\n",
    "2. Removing special characters and numbers\n",
    "3. Removing stopwords\n",
    "4. Tokenizing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d7637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"Preprocess text data for sentiment analysis.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        The input text to preprocess\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Preprocessed text\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Join tokens back into a string\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ba2f9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Steam reviews for App ID: 578080\n",
      "Target: 2000 reviews, Type: all, Language: english\n",
      "--------------------------------------------------\n",
      "Fetched 100 reviews so far...\n",
      "Fetched 100 reviews so far...\n",
      "Fetched 200 reviews so far...\n",
      "Fetched 200 reviews so far...\n",
      "Fetched 300 reviews so far...\n",
      "Fetched 300 reviews so far...\n",
      "Fetched 400 reviews so far...\n",
      "Fetched 400 reviews so far...\n",
      "Fetched 500 reviews so far...\n",
      "Fetched 500 reviews so far...\n",
      "Fetched 600 reviews so far...\n",
      "Fetched 600 reviews so far...\n",
      "Fetched 700 reviews so far...\n",
      "Fetched 700 reviews so far...\n",
      "Fetched 800 reviews so far...\n",
      "Fetched 800 reviews so far...\n",
      "Fetched 900 reviews so far...\n",
      "Fetched 900 reviews so far...\n",
      "Fetched 1000 reviews so far...\n",
      "Fetched 1000 reviews so far...\n",
      "Fetched 1100 reviews so far...\n",
      "Fetched 1100 reviews so far...\n",
      "Fetched 1200 reviews so far...\n",
      "Fetched 1200 reviews so far...\n",
      "Fetched 1300 reviews so far...\n",
      "Fetched 1300 reviews so far...\n",
      "Fetched 1400 reviews so far...\n",
      "Fetched 1400 reviews so far...\n",
      "Fetched 1500 reviews so far...\n",
      "Fetched 1500 reviews so far...\n",
      "Fetched 1600 reviews so far...\n",
      "Fetched 1600 reviews so far...\n",
      "Fetched 1700 reviews so far...\n",
      "Fetched 1700 reviews so far...\n",
      "Fetched 1800 reviews so far...\n",
      "Fetched 1800 reviews so far...\n",
      "Fetched 1900 reviews so far...\n",
      "Fetched 1900 reviews so far...\n",
      "Fetched 2000 reviews so far...\n",
      "Fetched 2000 reviews so far...\n",
      "\n",
      "Completed! Fetched 2000 reviews total\n",
      "Total reviews collected: 2000\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "Negative    1367\n",
      "Positive     633\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Preprocessing reviews...\n",
      "\n",
      "Completed! Fetched 2000 reviews total\n",
      "Total reviews collected: 2000\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "Negative    1367\n",
      "Positive     633\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Preprocessing reviews...\n"
     ]
    }
   ],
   "source": [
    "# Load PUBG reviews from parquet file\n",
    "reviews_df = pd.read_parquet('pubg_reviews.parquet')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Total reviews collected: {len(reviews_df)}\")\n",
    "print(\"\\nSentiment distribution:\")\n",
    "print(reviews_df['sentiment'].value_counts())\n",
    "\n",
    "# Preprocess reviews\n",
    "print(\"\\nPreprocessing reviews...\")\n",
    "reviews_df['processed_review'] = reviews_df['review'].apply(preprocess_text)\n",
    "\n",
    "# Prepare features and labels\n",
    "X = reviews_df['processed_review']\n",
    "y = reviews_df['voted_up']  # True for positive, False for negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bc1086",
   "metadata": {},
   "source": [
    "## Training the SVM Model\n",
    "Now we'll:\n",
    "1. Convert text to TF-IDF features\n",
    "2. Split the data into training and testing sets\n",
    "3. Train the SVM model\n",
    "4. Evaluate its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "467df4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data shape: (1600, 5000)\n",
      "Testing data shape: (400, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Convert text to TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tfidf,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "273df93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM model...\n",
      "\n",
      "Accuracy: 84.25%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.85      0.95      0.90       291\n",
      "    Positive       0.79      0.57      0.66       109\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.82      0.76      0.78       400\n",
      "weighted avg       0.84      0.84      0.83       400\n",
      "\n",
      "\n",
      "Accuracy: 84.25%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.85      0.95      0.90       291\n",
      "    Positive       0.79      0.57      0.66       109\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.82      0.76      0.78       400\n",
      "weighted avg       0.84      0.84      0.83       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the SVM model with probability estimation enabled\n",
    "print(\"\\nTraining SVM model...\")\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42, probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18e4bbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing sentiment analyzer with example reviews:\n",
      "\n",
      "Review: This game is amazing! Great gameplay and graphics.\n",
      "Sentiment: Positive\n",
      "Probability scores:\n",
      "- Positive: 99.63%\n",
      "- Negative: 0.37%\n",
      "\n",
      "Review: Terrible optimization, lots of bugs and hackers.\n",
      "Sentiment: Negative\n",
      "Probability scores:\n",
      "- Positive: 6.51%\n",
      "- Negative: 93.49%\n",
      "\n",
      "Review: Really enjoyed playing with friends, good battle royale experience.\n",
      "Sentiment: Positive\n",
      "Probability scores:\n",
      "- Positive: 95.70%\n",
      "- Negative: 4.30%\n",
      "\n",
      "Review: Lots of fun, but the matchmaking is terrible.\n",
      "Sentiment: Negative\n",
      "Probability scores:\n",
      "- Positive: 41.08%\n",
      "- Negative: 58.92%\n",
      "\n",
      "Review: It's okay, not the best but not the worst either.\n",
      "Sentiment: Positive\n",
      "Probability scores:\n",
      "- Positive: 55.19%\n",
      "- Negative: 44.81%\n",
      "\n",
      "Review: I had a lot of fun, but there are some issues that need fixing.\n",
      "Sentiment: Positive\n",
      "Probability scores:\n",
      "- Positive: 82.82%\n",
      "- Negative: 17.18%\n"
     ]
    }
   ],
   "source": [
    "def analyze_sentiment(text: str, model, vectorizer) -> tuple:\n",
    "    \"\"\"Analyze the sentiment of a given text using the trained model.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        The text to analyze\n",
    "    model : sklearn model\n",
    "        Trained model\n",
    "    vectorizer : TfidfVectorizer\n",
    "        Fitted vectorizer\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        Contains (sentiment prediction, probability scores dictionary)\n",
    "    \"\"\"\n",
    "    # Preprocess the text\n",
    "    processed_text = preprocess_text(text)\n",
    "\n",
    "    # Vectorize\n",
    "    text_vectorized = vectorizer.transform([processed_text])\n",
    "\n",
    "    # Get prediction and probabilities\n",
    "    prediction = model.predict(text_vectorized)[0]\n",
    "    probabilities = model.predict_proba(text_vectorized)[0]\n",
    "\n",
    "    # Create probability dictionary\n",
    "    prob_dict = {\n",
    "        'Negative': probabilities[0],\n",
    "        'Positive': probabilities[1]\n",
    "    }\n",
    "\n",
    "    return ('Positive' if prediction else 'Negative', prob_dict)\n",
    "\n",
    "# Test the analyzer with some example reviews\n",
    "example_reviews = [\n",
    "    \"This game is amazing! Great gameplay and graphics.\",\n",
    "    \"Terrible optimization, lots of bugs and hackers.\",\n",
    "    \"Really enjoyed playing with friends, good battle royale experience.\",\n",
    "    \"Lots of fun, but the matchmaking is terrible.\",\n",
    "    \"It's okay, not the best but not the worst either.\",\n",
    "    \"I had a lot of fun, but there are some issues that need fixing.\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting sentiment analyzer with example reviews:\")\n",
    "for review in example_reviews:\n",
    "    sentiment, probabilities = analyze_sentiment(review, svm_model, tfidf)\n",
    "    print(f\"\\nReview: {review}\")\n",
    "    print(f\"Sentiment: {sentiment}\")\n",
    "    print(f\"Probability scores:\")\n",
    "    print(f\"- Positive: {probabilities['Positive']:.2%}\")\n",
    "    print(f\"- Negative: {probabilities['Negative']:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
