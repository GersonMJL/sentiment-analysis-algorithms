{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e1718e6",
   "metadata": {},
   "source": [
    "# Steam Reviews Sentiment Analysis for PUBG: Battlegrounds using Naive Bayes\n",
    "\n",
    "This notebook performs sentiment analysis on Steam reviews for PUBG: Battlegrounds using a Naive Bayes algorithm. We'll load the reviews from a parquet file, preprocess the text data, and train a Naive Bayes model to classify reviews as positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24d174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Gerson\n",
      "[nltk_data]     Leite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Gerson\n",
      "[nltk_data]     Leite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Gerson\n",
      "[nltk_data]     Leite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Gerson Leite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a45259f",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "Let's load the PUBG reviews and prepare them for sentiment analysis:\n",
    "1. Load reviews from parquet file\n",
    "2. Preprocess the text data\n",
    "3. Create features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2047db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"Preprocess text data for sentiment analysis.\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Join tokens back into a string\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d1b059",
   "metadata": {},
   "source": [
    "## Data Collection and Preprocessing\n",
    "Let's fetch PUBG reviews and prepare them for sentiment analysis:\n",
    "1. Fetch reviews from Steam API\n",
    "2. Preprocess the text data\n",
    "3. Create features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25384ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Steam reviews for App ID: 578080\n",
      "Target: 2000 reviews, Type: all, Language: english\n",
      "--------------------------------------------------\n",
      "Fetched 100 reviews so far...\n",
      "Fetched 100 reviews so far...\n",
      "Fetched 200 reviews so far...\n",
      "Fetched 200 reviews so far...\n",
      "Fetched 300 reviews so far...\n",
      "Fetched 300 reviews so far...\n",
      "Fetched 400 reviews so far...\n",
      "Fetched 400 reviews so far...\n",
      "Fetched 500 reviews so far...\n",
      "Fetched 500 reviews so far...\n",
      "Fetched 600 reviews so far...\n",
      "Fetched 600 reviews so far...\n",
      "Fetched 700 reviews so far...\n",
      "Fetched 700 reviews so far...\n",
      "Fetched 800 reviews so far...\n",
      "Fetched 800 reviews so far...\n",
      "Fetched 900 reviews so far...\n",
      "Fetched 900 reviews so far...\n",
      "Fetched 1000 reviews so far...\n",
      "Fetched 1000 reviews so far...\n",
      "Fetched 1100 reviews so far...\n",
      "Fetched 1100 reviews so far...\n",
      "Fetched 1200 reviews so far...\n",
      "Fetched 1200 reviews so far...\n",
      "Fetched 1300 reviews so far...\n",
      "Fetched 1300 reviews so far...\n",
      "Fetched 1400 reviews so far...\n",
      "Fetched 1400 reviews so far...\n",
      "Fetched 1500 reviews so far...\n",
      "Fetched 1500 reviews so far...\n",
      "Fetched 1600 reviews so far...\n",
      "Fetched 1600 reviews so far...\n",
      "Fetched 1700 reviews so far...\n",
      "Fetched 1700 reviews so far...\n",
      "Fetched 1800 reviews so far...\n",
      "Fetched 1800 reviews so far...\n",
      "Fetched 1900 reviews so far...\n",
      "Fetched 1900 reviews so far...\n",
      "Fetched 2000 reviews so far...\n",
      "Fetched 2000 reviews so far...\n",
      "\n",
      "Completed! Fetched 2000 reviews total\n",
      "Total reviews collected: 2000\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "Negative    1367\n",
      "Positive     633\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Preprocessing reviews...\n",
      "\n",
      "Completed! Fetched 2000 reviews total\n",
      "Total reviews collected: 2000\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "Negative    1367\n",
      "Positive     633\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Preprocessing reviews...\n"
     ]
    }
   ],
   "source": [
    "# Load PUBG reviews from parquet file\n",
    "reviews_df = pd.read_parquet('pubg_reviews.parquet')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Total reviews collected: {len(reviews_df)}\")\n",
    "print(\"\\nSentiment distribution:\")\n",
    "print(reviews_df['sentiment'].value_counts())\n",
    "\n",
    "# Preprocess reviews\n",
    "print(\"\\nPreprocessing reviews...\")\n",
    "reviews_df['processed_review'] = reviews_df['review'].apply(preprocess_text)\n",
    "\n",
    "# Prepare features and labels\n",
    "X = reviews_df['processed_review']\n",
    "y = reviews_df['voted_up']  # True for positive, False for negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15009b3",
   "metadata": {},
   "source": [
    "## Training the Naive Bayes Model\n",
    "Now we'll:\n",
    "1. Convert text to TF-IDF features\n",
    "2. Split the data into training and testing sets\n",
    "3. Train the Naive Bayes model\n",
    "4. Evaluate its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "661cec1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data shape: (1600, 5000)\n",
      "Testing data shape: (400, 5000)\n",
      "\n",
      "Training Naive Bayes model...\n",
      "\n",
      "Accuracy: 76.00%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.76      0.99      0.86       291\n",
      "    Positive       0.84      0.15      0.25       109\n",
      "\n",
      "    accuracy                           0.76       400\n",
      "   macro avg       0.80      0.57      0.55       400\n",
      "weighted avg       0.78      0.76      0.69       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert text to TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tfidf,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n",
    "\n",
    "# Initialize and train the Naive Bayes model\n",
    "print(\"\\nTraining Naive Bayes model...\")\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2b752ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction probabilities:\n",
      "\n",
      "Review: Lots of fun, but the matchmaking is terrible.\n",
      "Negative probability: 78.06%\n",
      "Positive probability: 21.94%\n",
      "\n",
      "Review: It's okay, not the best but not the worst either.\n",
      "Negative probability: 75.14%\n",
      "Positive probability: 24.86%\n",
      "\n",
      "Review: I had a lot of fun, but there are some issues that need fixing.\n",
      "Negative probability: 79.91%\n",
      "Positive probability: 20.09%\n",
      "\n",
      "Review: While the game has potential, it suffers from numerous bugs.\n",
      "Negative probability: 73.41%\n",
      "Positive probability: 26.59%\n",
      "\n",
      "Review: Best battle royale game ever, highly recommended!\n",
      "Negative probability: 41.09%\n",
      "Positive probability: 58.91%\n"
     ]
    }
   ],
   "source": [
    "def analyze_sentiment(text: str, model, vectorizer) -> str:\n",
    "    \"\"\"Analyze the sentiment of a given text using the trained model.\"\"\"\n",
    "    # Preprocess the text\n",
    "    processed_text = preprocess_text(text)\n",
    "\n",
    "    # Vectorize\n",
    "    text_vectorized = vectorizer.transform([processed_text])\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(text_vectorized)[0]\n",
    "\n",
    "    return 'Positive' if prediction else 'Negative'\n",
    "\n",
    "# Test the analyzer with some example reviews\n",
    "example_reviews = [\n",
    "    \"Lots of fun, but the matchmaking is terrible.\",\n",
    "    \"It's okay, not the best but not the worst either.\",\n",
    "    \"I had a lot of fun, but there are some issues that need fixing.\",\n",
    "    \"While the game has potential, it suffers from numerous bugs.\",\n",
    "    \"Best battle royale game ever, highly recommended!\"\n",
    "]\n",
    "\n",
    "# print(\"\\nTesting sentiment analyzer with example reviews:\")\n",
    "# for review in example_reviews:\n",
    "#     sentiment = analyze_sentiment(review, nb_model, tfidf)\n",
    "#     print(f\"\\nReview: {review}\")\n",
    "#     print(f\"Sentiment: {sentiment}\")\n",
    "\n",
    "# Calculate prediction probabilities for the example reviews\n",
    "print(\"\\nPrediction probabilities:\")\n",
    "for review in example_reviews:\n",
    "    processed_text = preprocess_text(review)\n",
    "    text_vectorized = tfidf.transform([processed_text])\n",
    "    probs = nb_model.predict_proba(text_vectorized)[0]\n",
    "    print(f\"\\nReview: {review}\")\n",
    "    print(f\"Negative probability: {probs[0]:.2%}\")\n",
    "    print(f\"Positive probability: {probs[1]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49016720",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "Key differences between Naive Bayes and SVM for sentiment analysis:\n",
    "\n",
    "1. **Speed**: Naive Bayes is typically faster to train than SVM, especially on large datasets\n",
    "2. **Probability Output**: Naive Bayes naturally provides probability estimates\n",
    "3. **Assumptions**: Naive Bayes assumes feature independence, while SVM doesn't make this assumption\n",
    "4. **Memory Usage**: Naive Bayes typically uses less memory than SVM\n",
    "5. **Performance**: While both models can perform well, SVM might handle complex decision boundaries better\n",
    "\n",
    "The choice between them often depends on:\n",
    "- Dataset size\n",
    "- Training time requirements\n",
    "- Need for probability estimates\n",
    "- Available computational resources"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
